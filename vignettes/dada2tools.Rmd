---
title: "dada2tools"
output:
  rmarkdown::html_vignette
vignette: |
  %\VignetteIndexEntry{dada2tools} 
  %\VignetteEngine{knitr::rmarkdown} 
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE, cache=TRUE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = TRUE
)
```

```{r setup, results='hide'}
library(dada2)
library(dplyr)
library(phyloseq)
library(dada2tools)
library(stringr)
library(readxl)
library(openxlsx)
library(vegan)
library(ecodist)
library(RPushbullet)
library(magrittr)
library(pdftools)
library(ComplexHeatmap)
library(ggplot2)
library(purrr)
library(knitr)
library(flextable)
library(officer)
library(circlize)
library(seqinr)
library(here)
```
# Introduction to dada2tools

This package was written for researchers using DADA2 for their 16s rRNA sequencing data analysis. It allows easy construction of PCoA plots, heatmaps, and more. This vignette walks the reader through each of the functions in the order that they should be run with detailed examples and helpful notes.


# Contents

***

## 1. [Loading The Data Set](#Loading)
## 2. [Check Column Types](#Check)
## 3. [Cleaning The Data Set](#Cleaning)
###      + [Data Preparation](#Data)
###      + [Filtering Taxa](#Filtering)
####        + [Removing Taxa in Controls](#Removing)
###      + [Normalization](#Normalization)
## 4. [Named List Creation](#Named)
## 5. [Beta Diversity Plotting](#Beta)
## 6. [Heatmapping](#Heatmapping)
###    + [Preparation for Heatmapping](#Preparation)
###    + [Plotting Heatmaps](#Plotting)
###    + [Agglomeration](#Agglomeration)
## 7. [DECONTAM](#Decontam)
###    + [How to Set the Threshold](#How)
####      + [Prepare the Data Set](#Prepare)
####      + [Plot the Data](#Plot)
###    + [Run Decontam with Appropriate Threshold](#Run)
## 8. [Finishing Up](#Finishing)

***
## Loading The Data Set {#Loading}

After running DADA2 on a study data set, the results must be loaded into R. DADA2 outputs a taxa table along with an ASV table. These must be merged with taxa as rows and samples as columns.

This can be done with:
```{r eval=FALSE}
merged <- cbind(taxa.species, t(seqtab.nochim))
```

If DADA2 was run using the `Example_Script.R` within this package, the output will already be in the correct format.

To access the script, which is run in three blocks, use:
```{r eval= FALSE}
ES <- here::here("inst", "extdata", "Example_Script.R")
file.edit(ES)
```

It will also have been saved as a `merged.csv` file which can be loaded with:
```{r eval = FALSE}
#read.csv("~/path/to/file.csv", stringsAsFactors = FALSE)
Theis_merged <- read.csv(here("data-raw", "Theis_merged.csv"), stringsAsFactors = FALSE)
```

### Check Column Types {#Check}

It is always good practice to make sure that all numeric columns are actually of type numeric and all character columns are actually of type character. R will often convert characters and sometimes numbers to factors. This can be a real issue since the data looks exactly the same.

```{r}
Theis_merged

#We can use convert_merged() to ensure that all columns are of the proper type. `char_range` is the column range for taxonomy and num_range is the column range for the ASV/OTU table.

Theis_merged <- convert_merged(merged = Theis_merged, char_range = 1:8, num_range = 9:ncol(Theis_merged))
```

***

## Cleaning The Data Set {#Cleaning}

Now that the data set is loaded into the global environment we can begin to clean it up.

***

### Data Preparation {#Data}

In order to work with the ASV/OTU table we need to prepare metadata to filter/select for specific samples. This metadata is often found on the NCBI SRA Run Selector in association with the files to be downloaded. The downloaded metadata file (SraRunTable.txt) can then be converted to .csv by simply changing the extension from .txt to .csv. However, in order to use the metadata we first need to organize and match it to the samples in the ASV/OTU table. Relevant columns for this study include `Run` and `Library.Name`. Be aware that relevant columns can vary from study to study.

This can then be imported into R using:
```{r, eval=FALSE}
#read.csv("path/to/file.csv", stringsAsFactors = FALSE)
Theis_META <- read.csv(here("data-raw", "Theis_SraRunTable.csv"), stringsAsFactors = FALSE)
```

The `Theis_META` data file in this package is an example of what metadata will look like. Note that in the merged data set and the metadata, the SRR numbers are in order. Make sure they match each other:
```{r}
library(dplyr)
#using example metadata from package

for (i in 1:length(Theis_META$Run)){
    if (str_detect(string = Theis_META$Library.Name[i], pattern = "AC")|str_detect(string = Theis_META$Library.Name[i], pattern = "V")){
        Theis_META$Type[i] <- "Placenta"
        Theis_META$GA[i] <- "Term"
        Theis_META$Delivery[i] <- "Cesarean"
    } else {
        Theis_META$Type[i] <- "Technical Control"
        Theis_META$GA[i] <- NA
        Theis_META$Delivery[i] <- NA
    }
}

#filter metadata to a subset of the samples which were PCR amplified for a standard 30 cycles.
Theis_META_filt <- Theis_META %>% filter(LibrarySource == "METAGENOMIC") %>% select_if(colnames(.) %in% c("Run", "Library.Name", "Type", "GA", "Delivery"))

#We will only be using a subset of the samples which were PCR amplified for a standard 30 cycles.
Theis_ASV <- Theis_merged %>% select_if(., is.numeric) %>% select_if(colnames(.) %in% Theis_META_filt$Run)
Theis_TAX <- Theis_merged[, 1:8]
Theis_merged2 <- cbind(Theis_TAX, Theis_ASV)
```

***
### Filtering Taxa {#Filtering}

We now have to remove taxa which do not meet our filter parameters.

1. Bacterial in origin.
2. Classified at least down to Phylum
3. Not mitochondrial
4. Not chloroplast

We will also remove any samples which do not have at least 200 reads after filtering.

This is all done with `dadaset_clean()` which will also give an output listing samples eliminated from further analysis.
```{r}
#filtering process
Theis_merged_clean <- dadaset_clean(df = Theis_merged2, read_thresh = 100)
#give each ASV a number
rownames(Theis_merged_clean) <- paste0("ASV", 1:nrow(Theis_merged_clean))

#order metadata based on run names.
Theis_META_order <- Theis_META_filt[order(Theis_META_filt$Run),]

#order merged dataset
Theis_merged_order <- cbind(Theis_merged_clean[,1:8], Theis_merged_clean[,9:ncol(Theis_merged_clean)] %>% .[,order(colnames(.))])

#Ensure that samples not present in ASV table are not present in metadata either.
Theis_META_order <- Theis_META_order %>% filter(Run %in% colnames(Theis_merged_clean))

#if the following boolean vector is all `TRUE`, we can move on.
colnames(Theis_merged_order)[9:ncol(Theis_merged_order)] == Theis_META_order$Run
```

***

#### Removing Taxa in Controls {#Removing}

A more aggressive filtering method which removes all taxa found in technical controls can be used if desired.
```{r}
'%ni%' <- Negate('%in%')
Theis_tech_control_samples <- Theis_merged_order[,9:ncol(Theis_merged_order)] %>% select_if(Theis_META_order$Type == "Technical Control")
TC_taxa <- Theis_tech_control_samples %>% filter(rowSums(.) > 0) %>% rownames(.)

#remove technical control taxa from merged dataset

Theis_no_TC_taxa <- Theis_merged_order %>% filter(rownames(.) %ni% TC_taxa)

#need to remove control samples
Theis_TC_Removed <- dadaset_clean(Theis_no_TC_taxa, read_thresh = 1)
```

### Normalization {#Normalization}

Sampling depth can vary drastically with placental samples and therefore, before any analysis is done, the sampling depth needs to be normalized. Here, we use subsampling with the function `phyloseq::rarefy_even_depth()`.

```{r}
#first we convert the merged dataset into a phyloseq object
Theis_phy <- phyloseqize(merged_df = Theis_merged_order, taxa_as_rows = TRUE, keep_ASV_nums = TRUE)

#here we guarantee that the lowest sampling depth will be 100. subsampling is also pseudorandom, so for reproducibility the seed is set to `1`.
Theis_phy_rare <- phyloseq::rarefy_even_depth(physeq = Theis_phy, sample.size = max(min(sample_sums(Theis_phy)), 100), rngseed = 1, replace = FALSE)

#Conversion back to dataframe for further analysis.
Theis_rare <- dephy(phyloseq_obj = Theis_phy_rare)

Theis_rare_ASV <- Theis_rare[,9:ncol(Theis_rare)]
Theis_rare_TAX <- Theis_rare[,1:8]
Theis_rare_META <- Theis_META_order %>% filter(Run %in% colnames(Theis_rare_ASV))
Theis_rare_META <- Theis_rare_META %>% mutate(Del_GA = paste(Delivery, GA))
Theis_rare_META$Del_GA <- Theis_rare_META$Del_GA %>% recode(., "NA NA" = "Technical Control")
colnames(Theis_rare_META)[2] <- "Sample"
Theis_rare_META$Level <- case_when(
    str_detect(Theis_rare_META$Sample, pattern = "C$") ~ "Amnion-Chorion",
    str_detect(Theis_rare_META$Sample, pattern = "V$") ~ "Villous Tree",
    str_detect(Theis_rare_META$Type, pattern = "Technical Control") ~ "Technical Control"
)
```
### Subsets {#Subsets}

It can be useful to subset a dataset to only samples of a particular type. This is quite straightforward with dplyr piping (`%>%`).

```{r}
#Only Placental Samples.
Theis_ASV_P <- Theis_rare_ASV %>% select_if(Theis_rare_META$Type == "Placenta")
Theis_ASV_P <- Theis_ASV_P %>% filter(rowSums(.) > 0)
Theis_META_P <- Theis_rare_META %>% filter(Type == "Placenta")
Theis_TAX_P <- Theis_rare_TAX %>% filter(rownames(.) %in% rownames(Theis_ASV_P))

```

***
## Named List creation {#Named}

In some cases we'll need to create a named list. Through base R it can be done by:

 `example_list <- list("name1" = 28, "name2" = 41, "name3" = 29)`

***

## Beta Diversity Plotting {#Beta}

To analyze the structure of the samples in this data set we will be creating PCoA plots of Bray-Curtis dissimilarity indices. Once the data set is cleaned and normalized, a plot can be generated using `beta_div()`. On top of that plot, weighted average genus labels of select ASVs can be plotted using `WA_labels()`. 

```{r fig.width= 7, fig.height= 7}

palette(c("red", "black"))
par(xpd = FALSE)
Theis_Beta_plot_PTCWA <- beta_div(df = Theis_rare_ASV, df_meta = Theis_rare_META, type = "Type", study = "Example Plot", all_O = TRUE, taxa_on_rows = TRUE, size = 2, legendyn = FALSE)
Theis_topASVs <- rowSums(Theis_rare_ASV) %>% sort(., decreasing = TRUE) %>% head(., 10)
par(xpd = FALSE)
WA_labels(Plot_object = Theis_Beta_plot_PTCWA, ASV_table = Theis_rare_ASV, TAX_table = Theis_rare_TAX, ASVs_on_rows = TRUE, ASV_with_Genus = FALSE, Tax_col = "Genus", color = "grey", Greater_than_1per = FALSE, ASVs_to_plot = names(Theis_topASVs))
```

If the plot needs to be rotated for better comparison to a related PCoA plot, the `invert_x` and `invert_y` arguments can be used to correct the plot orientation.
```{r, animation.hook= "gifski", fig.width=7, fig.height=6}
beta_div(df = Theis_rare_ASV, df_meta = Theis_rare_META, type = "Type", study = "Inverted Over Y axis", all_O = TRUE, taxa_on_rows = TRUE, size = 2, legendyn = FALSE, invert_x = TRUE)
beta_div(df = Theis_rare_ASV, df_meta = Theis_rare_META, type = "Type", study = "Inverted Over X axis", all_O = TRUE, taxa_on_rows = TRUE, size = 2, legendyn = FALSE, invert_y = TRUE)
beta_div(df = Theis_rare_ASV, df_meta = Theis_rare_META, type = "Type", study = "Inverted Over Both Axes", all_O = TRUE, taxa_on_rows = TRUE, size = 2, legendyn = FALSE, invert_x = TRUE, invert_y = TRUE)
```

After generating the desired PCoA plot(s), we can now move on to heatmapping.

***

## Heatmapping {#Heatmapping}

This package uses the Heatmap function from the `ComplexHeatmap` package, which is very useful. Detailed tutorials can be found in the [ComplexHeatmap Complete Reference](https://jokergoo.github.io/ComplexHeatmap-reference/book/).

However, before we can get to that part, we need to prepare the data set for heatmapping.

### Preparation for Heatmapping {#Preparation}

Our data set is clean, but now we need to transform it so that genera classifications are column names, samples are on rows, and the data set is strictly of type numeric. To do all of this we use `heatmap_prep()`. Several very important ASV selection arguments are `mean_ab_by_type`, `mean_ab_cutoff`, `select_ASVs`, and `taxa_cutoff`. Since heatmapping over 900 taxa is a bit too much and because we are interested in taxa which make up a large portion of the samples, we can employ cutoffs to slim down the data set. All arguments apply cutoffs, but in different ways. 

Only one option can be used at a time. They will be evaluated in the order listed so if `mean_ab_by_type` is passed a character vector, no other selection methods will be used.

`mean_ab_by_type` has no default but if passed a character vector of a column in `df_meta`, will be used to split samples into types before calculating mean percent relative abundance and selecting ASVs.

`mean_ab_cutoff` applies a mean proportional cutoff, which only retains taxa with a mean percentage of sample greater than 1%.

`select_ASVs` character vector of ASVs to select by ASV number, which should be rownames in `df_tax`.

`taxa_cutoff` applies a ranked abundance cutoff, which only retains taxa ranked above the cutoff number given i.e. `taxa_cutoff = 10` will keep the top 10 ranked taxa by abundance.

Note, only one cutoff should be applied at a time, and `mean_ab_cutoff` will not work correctly if used after `taxa_cutoff` since proportions will change if the total number of taxa is decreased.

```{r}
#Theis All Sample Types Heatmap
Theis_preheat_by_type <- heatmap_prep(df = Theis_rare_ASV, df_tax = Theis_rare_TAX, class_col = "Genus", df_meta = Theis_rare_META, mean_ab_by_type = "Level", mean_ab_cutoff = FALSE)

Theis_preheat_by_1pct_cutoff <- heatmap_prep(df = Theis_rare_ASV, df_tax = Theis_rare_TAX, class_col = "Genus", df_meta = Theis_rare_META, mean_ab_cutoff = TRUE)

Theis_preheat_top10 <- heatmap_prep(df = Theis_rare_ASV, df_tax = Theis_rare_TAX, class_col = "Genus", df_meta = Theis_rare_META, mean_ab_cutoff = FALSE, taxa_cutoff = 10)

Theis_topASVs <- get_top_ASVs(df = Theis_rare_ASV, number = 10, ASVs_on_Rows = TRUE)

Theis_preheat_top_ASVs <- heatmap_prep(df = Theis_rare_ASV, df_tax = Theis_rare_TAX, class_col = "Genus", df_meta = Theis_rare_META, select_ASVs = Theis_topASVs, mean_ab_cutoff = FALSE)
```

As we can see, the two data sets prepared for heatmapping look quite similar. 

### Plotting Heatmaps {#Plotting}

We are now ready to plot our first heatmap with `heatmapping()`. This function will produce a heatmap with samples grouped by sample type as defined in the named list. It has color scheme option of blue to red with `scalecolor = "red-blue"`. It also has the option to plot values by percentage of sample `by_percent = TRUE` or use total read counts for plotting `by_percent = FALSE`.

Note that we do not have to store the plot into anything to obtain a plot.

```{r fig.width=19, fig.height=8}

Theis_heatmap_All <- heatmapping(df = Theis_preheat_by_type, df_meta = Theis_rare_META, types_col = "Level", scalecolor = "red-blue", title = "Theis ASVs >1% by Type")
```

We can see the differences here:

```{r animation.hook= "gifski", fig.width=19, fig.height=8}

heatmapping(df = Theis_preheat_top_ASVs, df_meta = Theis_rare_META, types_col = "Level", scalecolor = "red-blue", title = "Theis ASVs >1% by Type", by_percent = TRUE)
heatmapping(df = Theis_preheat_top_ASVs, df_meta = Theis_rare_META, types_col = "Level", scalecolor = "red-blue", title = "Theis ASVs >1% by Type", by_percent = FALSE)
```

***

### Agglomeration {#Agglomeration}

Agglomeration can be used to observe patterns in taxonomic data at many levels, not just the ASV level. Agglomeration is performed with `agglomerate()` on the normalized dataset.

```{r}
Theis_agg <- agglomerate(df = Theis_rare_ASV,df_tax = Theis_rare_TAX, agg_class = "Genus")
Theis_agg_tax <- data.frame(Genus = rownames(Theis_agg), row.names = rownames(Theis_agg))
Theis_agg_P <- Theis_agg %>% select_if(colnames(.) %in% Theis_META_P$Run)
Theis_agg_tax_P <- Theis_agg_tax %>% filter(rownames(.) %in% rownames(Theis_agg_P))

Theis5 <- get_top_ASVs(Theis_agg_P, 5)
```


***

## DECONTAM {#Decontam}

For detailed instructions and tutorials on how to run DECONTAM or Phyloseq, please visit [Decontam Reference](https://benjjneb.github.io/decontam/vignettes/decontam_intro.html), and [Phyloseq Reference](https://joey711.github.io/phyloseq/).

This package utilizes both `DECONTAM` and `Phyloseq` to obtain a data set relatively free of contaminants. `DECONTAM` has two methods of determining contaminants. A prevalence method, which is utilized in this package, and a frequency method which is not. If possible, it is advisable to use both. The prevalence method relies on the assumption that taxa that are more prevalent in negative control samples are contaminants and taxa that are more prevalent in regular samples are true taxa. However, when dealing with low read count samples such as what can be obtained from sequencing placental samples, taxa can appear equally in both negative controls and regular samples. `DECONTAM` employs an adjustable DECONTAM score threshold which ranges from 0.0 to 1.0. As the threshold gets lower, more taxa are considered contaminants. The threshold cutoff selected can be somewhat subjective. A good rule of thumb is that if taxa from negative controls are still showing in regular samples in high abundances, the threshold is too low.

### How to Set the Threshold {#How}


#### Prepare the Data Set {#Prepare}

With this package it is quite easy. First, we need to go back to our original `merged_clean` data set. DECONTAM is always run before normalization. From there, we use `decontam_prep()` to prepare the data set.

```{r}
#a column in Theis_META_order needs to indicate samples as either "sample" or "control"
Theis_META_order$Deco_type <- case_when(Theis_META_order$Type == "Placenta" ~ "sample", Theis_META_order$Type == "Technical Control" ~ "control")

DECO_prep <- decontam_prep(df = Theis_merged_order, meta = Theis_META_order, type = "Deco_type", sample_col = "Run")
```

#### Plot the Data {#Plot}

Now that our data set is prepared. We can run `decontam_histo_prev_plots()`. At this point, the threshold we choose doesn't matter. There should be a warning about removing rows containing non-finite values, but that can be ignored.

```{r fig.width=9, fig.height=7, warning= FALSE}
decontam_plots <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.1, study_name = "Theis")
decontam_plots$Histogram
```
The histogram generated looks at every single ASV and gives it a decontam score (how likely it is to be a contaminant). It also looks at how prevalent the ASV is and plots that as a deeper green hue. Finally, ASVs that share the same Decontam score are grouped on the bars with higher prevalence ASVs at the bottom. 

When making a decision for threshold value given low read count samples and a high likelihood of contamination, thresholds less than `0.5` and even less than `0.25` are appropriate. Multiple thresholds can be set to get an idea. For this data set, `0.10` was used as a final threshold. The rationale is that we are looking for highly prevalent taxa which have low decontam scores. At `0.06` and below we can see that ASVs have high prevalence and at `0.17` there is a spike of low prevalence ASVs; the former would be more likely to constitute a placental microbiome than the latter so we set a threshold in the middle.

```{r fig.width=9, fig.height=7}
decontam_plots$Prevalence_Plot
```

This Prevalence plot lets us take a different look at overall prevalence of taxa. Contaminants in blue are more likely to be found in negative controls than taxa in red. Again, going back and trying different thresholds is recommended.

```{r animation.hook= "gifski", fig.width= 9, fig.height=7}
decontam_plots.5 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.5, study_name = "Theis")
decontam_plots.4 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.4, study_name = "Theis")
decontam_plots.3 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.3, study_name = "Theis")
decontam_plots.2 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.2, study_name = "Theis")
decontam_plots.1 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.1, study_name = "Theis")
decontam_plots.5$Prevalence_Plot
decontam_plots.4$Prevalence_Plot
decontam_plots.3$Prevalence_Plot
decontam_plots.2$Prevalence_Plot
decontam_plots.1$Prevalence_Plot
```

### Run Decontam with Appropriate Threshold {#Run}

Once a threshold has been chosen, it is time to finally run `decontaminate()`. We still need the original data frame from when we started the process, plus the `Phyloseq` object created when `decontam_prep()` was run.

```{r}

Theis_decontaminated <- decontaminate(df = Theis_merged_order, physeq = DECO_prep, thresh = 0.1)
Theis_true_taxa <- Theis_decontaminated$TrueTaxa
head(Theis_true_taxa[,1:20], 5)

#contaminants can also be evaluated
Theis_contaminants <- Theis_decontaminated$Contaminants
head(Theis_contaminants[,1:20], 5)
```

`decontaminate()` will return a list of three objects. The true taxa data set, the contaminants, and the threshold which was used. It is important to note that `decontaminate()` uses the `isNotContaminant()` function, which is only appropriate for low biomass sites or low read count sites like the placenta.

***

## Finishing Up {#Finishing}

Now that we have a data set run through DECONTAM, we need to re-plot everything. We can take the `Theis_true_taxa` data set and use the same process to generate PCoA plots, and heatmaps. 

Note that for this pass with a decontaminated data set, it is recommended to use a taxa cutoff in heatmap prep instead of the mean abundance cutoff because decontam filtering will have already modified taxa proportions by removing contaminant taxa from the data set.

