---
title: "dada2tools"
author: "Jonathan Panzer"
output:
  rmarkdown::html_vignette
vignette: |
  %\VignetteIndexEntry{dada2tools} 
  %\VignetteEngine{knitr::rmarkdown} 
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE, cache=TRUE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = TRUE
)
```

# Setup

The following packages are required to run the code in the vignette.

```{r setup, results='hide'}
library(dada2)
library(dplyr)
library(phyloseq)
library(dada2tools)
library(stringr)
library(readxl)
library(openxlsx)
library(vegan)
library(ecodist)
library(RPushbullet)
library(magrittr)
library(pdftools)
library(ComplexHeatmap)
library(ggplot2)
library(purrr)
library(knitr)
library(flextable)
library(officer)
library(circlize)
library(seqinr)
library(here)
```
# Introduction to dada2tools

This package was written for researchers using DADA2 for their 16S rRNA sequencing data analysis. It allows easy construction of PCoA plots, heatmaps, and more. This vignette walks the reader through each of the functions in the order that they should be run with detailed examples and helpful notes.


# Contents

***

## 1. [Loading The Data Set](#Loading)
## 2. [Check Column Types](#Check)
## 3. [Cleaning The Data Set](#Cleaning)
###      + [Data Preparation](#Data)
###      + [Filtering Taxa](#Filtering)
####        + [Removing Taxa in Controls](#Removing)
###      + [Normalization](#Normalization)
## 4. [Named List Creation](#Named)
## 5. [Beta Diversity Plotting](#Beta)
## 6. [Heatmapping](#Heatmapping)
###    + [Preparation for Heatmapping](#Preparation)
###    + [Plotting Heatmaps](#Plotting)
###    + [Agglomeration](#Agglomeration)
## 7. [DECONTAM](#Decontam)
###    + [How to Set the Threshold](#How)
####      + [Prepare the Data Set](#Prepare)
####      + [Plot the Data](#Plot)
###    + [Run Decontam with Appropriate Threshold](#Run)
## 8. [Finishing Up](#Finishing)

***
## Loading The Data Set {#Loading}

After processing 16S rRNA gene sequencing data with DADA2, the results must be loaded into R. DADA2 outputs a taxa table along with an ASV table. These must be merged with the taxa as rows and samples as columns.

This can be done with:
```{r example_merging, eval=FALSE}
merged <- cbind(taxa.species, t(seqtab.nochim))
```

If DADA2 was run using the `Example_Script.R` within this package, the output will already be in the correct format.

To access the script, which is run in three blocks, use:
```{r example_script, eval= FALSE}
ES <- here::here("inst", "extdata", "Example_Script.R")
file.edit(ES)
```

The result of DADA2 processing: `merged.csv` will also have been saved and can be loaded as follows.

```{r reading_csv, eval = FALSE}
#read.csv("~/path/to/file.csv", stringsAsFactors = FALSE)
Theis_merged <- read.csv(here::here("data-raw", "Theis_merged.csv"), stringsAsFactors = FALSE)
```

### Check Column Types {#Check}

It is always good practice to make sure that all numeric columns are actually of type numeric and all character columns are actually of type character. R will often convert characters and sometimes numbers to factors. This can be a real issue since the data looks exactly the same.

```{r column_check}
str(Theis_merged)

#We can use convert_merged() to ensure that all columns are of the proper type. 
#`char_range` is the column range for taxonomy and num_range is the column range for the ASV/OTU table.

Theis_merged <- convert_merged(
  merged = Theis_merged, 
  char_range = 1:8, 
  num_range = 9:ncol(Theis_merged)
  )
```

***

## Cleaning The Data Set {#Cleaning}

Now that the data set is loaded into the global environment we can begin to clean it up.

***

### Data Preparation {#Data}

In order to work with the ASV/OTU table we need to prepare metadata to filter/select for specific samples. This metadata is often found on the NCBI SRA Run Selector in association with the files to be downloaded. The downloaded metadata file (SraRunTable.txt) can then be converted to .csv by simply changing the extension from .txt to .csv. However, in order to use the metadata we first need to organize and match it to the samples in the ASV/OTU table. Relevant columns for this study include `Run` and `Library.Name`. Be aware that relevant columns can vary from study to study.

This can then be imported into R using:
```{r initial_meta, eval=FALSE}
#read.csv("path/to/file.csv", stringsAsFactors = FALSE)
Theis_META <- read.csv(here("data-raw", "Theis_SraRunTable.csv"), stringsAsFactors = FALSE)
```

The `Theis_META` data file in this package is an example of what metadata will look like. Note that in the merged data set and the metadata, the SRR numbers are in order. Make sure they match each other:
```{r data_cleanup}
library(dplyr)
#using example metadata from package

for (i in 1:length(Theis_META$Run)){
    if (
        str_detect(string = Theis_META$Library.Name[i], pattern = "AC")|
        str_detect(string = Theis_META$Library.Name[i], pattern = "V")
       ){
        Theis_META$Type[i] <- "Placenta"
        Theis_META$GA[i] <- "Term"
        Theis_META$Delivery[i] <- "Cesarean"
    } else {
        Theis_META$Type[i] <- "Technical Control"
        Theis_META$GA[i] <- NA
        Theis_META$Delivery[i] <- NA
    }
}

#filter metadata to a subset of the samples which were PCR amplified for a standard 30 cycles.
Theis_META_filt <- Theis_META %>% 
  filter(LibrarySource == "METAGENOMIC") %>% 
  select_if(colnames(.) %in% c("Run", "Library.Name", "Type", "GA", "Delivery"))

#We will only be using a subset of the samples which were PCR amplified for a standard 30 cycles.
Theis_ASV <- Theis_merged %>% 
  select_if(., is.numeric) %>% 
  select_if(colnames(.) %in% Theis_META_filt$Run)
Theis_TAX <- Theis_merged[, 1:8]
Theis_merged2 <- cbind(Theis_TAX, Theis_ASV)
```

***
### Filtering Taxa {#Filtering}

We now have to remove taxa which do not meet our filter parameters.

1. Bacterial in origin.
2. Classified at least down to Phylum
3. Not mitochondrial
4. Not chloroplast

We will also remove any samples which do not have at least 200 reads after filtering.

This is all done with `dadaset_clean()`. In addition, the function will list how many taxa were removed for the four reasons listed above as well as the number of samples eliminated from further analysis.
```{r filtering_data}
#filtering process
Theis_merged_clean <- dadaset_clean(df = Theis_merged2, read_thresh = 100)
#give each ASV a number
rownames(Theis_merged_clean) <- paste0("ASV", 1:nrow(Theis_merged_clean))

#order metadata based on run names.
Theis_META_order <- Theis_META_filt[order(Theis_META_filt$Run),]

#order merged dataset
Theis_merged_order <- cbind(
  Theis_merged_clean[,1:8], 
  Theis_merged_clean[,9:ncol(Theis_merged_clean)] %>% .[,order(colnames(.))])

#Ensure that samples not present in ASV table are not present in metadata either.
Theis_META_order <- Theis_META_order %>% filter(Run %in% colnames(Theis_merged_clean))

#if the following boolean vector is all `TRUE`, we can move on.
colnames(Theis_merged_order)[9:ncol(Theis_merged_order)] == Theis_META_order$Run
```

***

#### Removing Taxa in Controls {#Removing}

A more aggressive filtering method which removes all taxa found in technical controls can be used if desired.
```{r removing_taxa}
'%ni%' <- Negate('%in%')
Theis_tech_control_samples <- Theis_merged_order[,9:ncol(Theis_merged_order)] %>% select_if(Theis_META_order$Type == "Technical Control")
TC_taxa <- Theis_tech_control_samples %>% filter(rowSums(.) > 0) %>% rownames(.)

#remove technical control taxa from merged dataset

Theis_no_TC_taxa <- Theis_merged_order %>% filter(rownames(.) %ni% TC_taxa)

#need to remove control samples
Theis_TC_Removed <- dadaset_clean(Theis_no_TC_taxa, read_thresh = 1)
```

### Normalization {#Normalization}

Sampling depth varies greatly with placental samples and therefore, before any analysis is done, the sampling depth needs to be normalized in order to make comparisons between different samples. Here, we utilize sub-sampling otherwise known as rarefaction with the function `phyloseq::rarefy_even_depth()`.

```{r normalization}
#first we convert the merged dataset into a phyloseq object
Theis_phy <- phyloseqize(
  merged_df = Theis_merged_order, 
  taxa_as_rows = TRUE, 
  keep_ASV_nums = TRUE
  )

#here we guarantee that the lowest sampling depth will be 100. subsampling is also pseudorandom, 
#so for reproducibility the seed is set to `1`.
Theis_phy_rare <- phyloseq::rarefy_even_depth(
  physeq = Theis_phy, 
  sample.size = max(min(sample_sums(Theis_phy)), 100), 
  rngseed = 1, 
  replace = FALSE
  )

#Conversion back to dataframe for further analysis.
Theis_rare <- dephy(phyloseq_obj = Theis_phy_rare)

Theis_rare_ASV <- Theis_rare[,9:ncol(Theis_rare)]
Theis_rare_TAX <- Theis_rare[,1:8]
Theis_rare_META <- Theis_META_order %>% filter(Run %in% colnames(Theis_rare_ASV))
Theis_rare_META <- Theis_rare_META %>% mutate(Del_GA = paste(Delivery, GA))
Theis_rare_META$Del_GA <- Theis_rare_META$Del_GA %>% recode(., "NA NA" = "Technical Control")
colnames(Theis_rare_META)[2] <- "Sample"
Theis_rare_META$Level <- case_when(
    str_detect(Theis_rare_META$Sample, pattern = "C$") ~ "Amnion-Chorion",
    str_detect(Theis_rare_META$Sample, pattern = "V$") ~ "Villous Tree",
    str_detect(Theis_rare_META$Type, pattern = "Technical Control") ~ "Technical Control"
)
```
### Subsets {#Subsets}

It can be useful to subset a dataset to only samples of a particular type. This is quite straightforward with dplyr piping (`%>%`).

```{r subsetting}
#Only Placental Samples.
Theis_ASV_P <- Theis_rare_ASV %>% select_if(Theis_rare_META$Type == "Placenta")
Theis_ASV_P <- Theis_ASV_P %>% filter(rowSums(.) > 0)
Theis_META_P <- Theis_rare_META %>% filter(Type == "Placenta")
Theis_TAX_P <- Theis_rare_TAX %>% filter(rownames(.) %in% rownames(Theis_ASV_P))

```

***
## Named List creation {#Named}

In some cases named lists will need to be created. Through base R it can be done by:

 `example_list <- list("name1" = 28, "name2" = 41, "name3" = 29)`

***

## Beta Diversity Plotting {#Beta}

To analyze the structure of the samples in this data set we create PCoA plots of Bray-Curtis dissimilarity indices. Once the data set is cleaned and normalized, a beta diversity plot can be generated using `beta_div()`. Weighted average genus labels of select ASVs can also be plotted on top of the PCoA using `WA_labels()`. 

```{r beta_diversity_plotting, fig.width= 7, fig.height= 7}

palette(c("red", "black"))
par(xpd = FALSE)
Theis_Beta_plot_PTCWA <- beta_div(
  df = Theis_rare_ASV, 
  df_meta = Theis_rare_META, 
  type = "Type", 
  study = "Example Plot", 
  all_O = TRUE, 
  taxa_on_rows = TRUE, 
  size = 2, 
  legendyn = FALSE)
Theis_topASVs <- rowSums(Theis_rare_ASV) %>% sort(., decreasing = TRUE) %>% head(., 10)
par(xpd = FALSE)
WA_labels(
  Plot_object = Theis_Beta_plot_PTCWA, 
  ASV_table = Theis_rare_ASV, 
  TAX_table = Theis_rare_TAX, 
  ASVs_on_rows = TRUE, 
  ASV_with_Genus = FALSE, 
  Tax_col = "Genus", 
  color = "grey", 
  Greater_than_1per = FALSE, 
  ASVs_to_plot = names(Theis_topASVs))
```

If the plot needs to be rotated for better comparison to a related PCoA plot, the `invert_x` and `invert_y` arguments can be used to correct the plot orientation. `invert_x` and `invert_y` refer to the desired axis over which the points will be inverted.
```{r inversions, animation.hook= "gifski", fig.width=7, fig.height=6}
x_inverted <- beta_div(
  df = Theis_rare_ASV, 
  df_meta = Theis_rare_META, 
  type = "Type", 
  study = "Inverted Over Y axis", 
  all_O = TRUE, 
  taxa_on_rows = TRUE, 
  size = 2, 
  legendyn = FALSE, 
  invert_x = TRUE)
y_inverted <- beta_div(
  df = Theis_rare_ASV, 
  df_meta = Theis_rare_META, 
  type = "Type", 
  study = "Inverted Over X axis", 
  all_O = TRUE, 
  taxa_on_rows = TRUE, 
  size = 2, 
  legendyn = FALSE, 
  invert_y = TRUE)
xy_inverted <- beta_div(
  df = Theis_rare_ASV, 
  df_meta = Theis_rare_META, 
  type = "Type", 
  study = "Inverted Over Both Axes", 
  all_O = TRUE, 
  taxa_on_rows = TRUE, 
  size = 2, 
  legendyn = FALSE, 
  invert_x = TRUE, 
  invert_y = TRUE)
```

After generating the desired PCoA plot(s), we can now focus on heatmapping.

***

## Heatmapping {#Heatmapping}

This package uses the `Heatmap()` function from the `ComplexHeatmap` package, which is very versatile. Detailed tutorials can be found in the [ComplexHeatmap Complete Reference](https://jokergoo.github.io/ComplexHeatmap-reference/book/).

However, prior to heatmapping, we need to prepare the data set.

### Preparation for Heatmapping {#Preparation}

Our data set is clean, but now we need to transform it so that genera classifications are column names, samples are on rows, and the data set is entirely of type `numeric`. To do all of this we use `heatmap_prep()`. Since heatmapping over 900 taxa could be overwhelming and because we are interested in taxa with high relative abundance, we employ cutoffs to trim the data set. Several  important ASV selection arguments are `mean_ab_by_type`, `mean_ab_cutoff`, `select_ASVs`, and `taxa_cutoff`. All these arguments apply cutoffs, but in different ways. 

Only one option can be used at a time. They will be evaluated in the order listed so if `mean_ab_by_type` is passed a character vector, no other selection methods will be used.

`mean_ab_by_type` has no default but if passed a character vector of a column in `df_meta`, will be used to split samples into types before calculating mean percent relative abundance and selecting ASVs.

`mean_ab_cutoff` applies a mean proportional cutoff, which only retains taxa with a mean percentage of sample greater than 1%.

`select_ASVs` character vector of ASVs to select by ASV number, which should be rownames in `df_tax`.

`taxa_cutoff` applies a ranked abundance cutoff, which only retains taxa ranked above the cutoff number given i.e. `taxa_cutoff = 10` will keep the top 10 ranked taxa by abundance.

Note, only one cutoff should be applied at a time, and `mean_ab_cutoff` will not work correctly if used after `taxa_cutoff` since proportions will change if the total number of taxa is reduced.

```{r heatmap_preparation}
#Theis All Sample Types Heatmap
Theis_preheat_by_type <- heatmap_prep(
  df = Theis_rare_ASV, 
  df_tax = Theis_rare_TAX, 
  class_col = "Genus", 
  df_meta = Theis_rare_META, 
  mean_ab_by_type = "Level", 
  mean_ab_cutoff = FALSE)

Theis_preheat_by_1pct_cutoff <- heatmap_prep(
  df = Theis_rare_ASV, 
  df_tax = Theis_rare_TAX, 
  class_col = "Genus", 
  df_meta = Theis_rare_META, 
  mean_ab_cutoff = TRUE)

Theis_preheat_top10 <- heatmap_prep(
  df = Theis_rare_ASV, 
  df_tax = Theis_rare_TAX, 
  class_col = "Genus", 
  df_meta = Theis_rare_META, 
  mean_ab_cutoff = FALSE, 
  taxa_cutoff = 10)

Theis_topASVs <- get_top_ASVs(df = Theis_rare_ASV, number = 10, ASVs_on_Rows = TRUE)

Theis_preheat_top_ASVs <- heatmap_prep(
  df = Theis_rare_ASV, 
  df_tax = Theis_rare_TAX, 
  class_col = "Genus", 
  df_meta = Theis_rare_META, 
  select_ASVs = Theis_topASVs, 
  mean_ab_cutoff = FALSE)
```

As we can see, the two data sets prepared for heatmapping look quite similar. 

### Plotting Heatmaps {#Plotting}

We are now ready to plot our first heatmap with `heatmapping()`. This function will produce a heatmap with samples grouped by sample type as defined in the named list. It has color scheme option of blue to red with `scalecolor = "red-blue"`. It also has the option to plot values by percentage of sample `by_percent = TRUE` or use total read counts for plotting `by_percent = FALSE`.

Note that we do not have to store the plot into anything to obtain a plot.

```{r heatmap_plot, fig.width=19, fig.height=8}

Theis_heatmap_All <- heatmapping(
  df = Theis_preheat_by_type, 
  df_meta = Theis_rare_META, 
  types_col = "Level", 
  scalecolor = "red-blue", 
  title = "Theis ASVs >1% by Type")
```

Note that once we have normalized the data, relative and absolute abundance give the same results.

```{r rel_and_abs_heatmap, animation.hook= "gifski", fig.width=19, fig.height=8}

heatmapping(
  df = Theis_preheat_top_ASVs, 
  df_meta = Theis_rare_META, 
  types_col = "Level", 
  scalecolor = "red-blue", 
  title = "Theis ASVs >1% by Type", 
  by_percent = TRUE)
heatmapping(
  df = Theis_preheat_top_ASVs, 
  df_meta = Theis_rare_META, 
  types_col = "Level", 
  scalecolor = "red-blue", 
  title = "Theis ASVs >1% by Type", 
  by_percent = FALSE)
```

***

### Agglomeration {#Agglomeration}

Agglomeration can be used to observe patterns in taxonomic data at many levels, not just the ASV level. For instance, agglomeration can be used to combine the abundances of ASVs with the same Genus level classification. Agglomeration is performed with `agglomerate()` on the normalized dataset.

```{r agglomeration}
Theis_agg <- agglomerate(df = Theis_rare_ASV,df_tax = Theis_rare_TAX, agg_class = "Genus")
Theis_agg_tax <- data.frame(Genus = rownames(Theis_agg), row.names = rownames(Theis_agg))
Theis_agg_P <- Theis_agg %>% select_if(colnames(.) %in% Theis_META_P$Run)
Theis_agg_tax_P <- Theis_agg_tax %>% filter(rownames(.) %in% rownames(Theis_agg_P))

Theis5 <- get_top_ASVs(Theis_agg_P, 5)
```


***

## DECONTAM {#Decontam}

For detailed instructions and tutorials on how to run DECONTAM or Phyloseq, please visit [Decontam Reference](https://benjjneb.github.io/decontam/vignettes/decontam_intro.html), and [Phyloseq Reference](https://joey711.github.io/phyloseq/).

This package utilizes both `DECONTAM` and `Phyloseq` to obtain a data set relatively free of contaminants. `DECONTAM` has two methods of determining contaminants. A prevalence method that is utilized in this package, and a frequency method that is not. If possible, it is advisable to use both. The prevalence method assumes that prevalent taxa in technical control samples are contaminants and prevalent taxa in regular samples are true taxa. However, when dealing with low read count samples, such as what can be obtained from sequencing placental samples, taxa can appear equally in both technical controls and regular samples. `DECONTAM` employs an adjustable DECONTAM score threshold which ranges from 0.0 to 1.0. As the threshold gets lower, more taxa are considered contaminants. The selection of a threshold cutoff can be somewhat subjective. However, a good rule of thumb is that if taxa from technical controls are still highly abundant in regular samples, the threshold is not stringent enough.

### How to Set the Threshold {#How}


#### Prepare the Data Set {#Prepare}

With this package it is quite easy to determine the appropriate threshold. First, we return to the original `merged_clean` data set. DECONTAM is always run before normalization. Next, we use `decontam_prep()` to prepare the data set (i.e. convert it to a `phyloseq` object).

```{r decontam_prep}
#a column in Theis_META_order needs to indicate samples as either "sample" or "control"
Theis_META_order$Deco_type <- case_when(
  Theis_META_order$Type == "Placenta" ~ "sample", 
  Theis_META_order$Type == "Technical Control" ~ "control")

DECO_prep <- decontam_prep(
  df = Theis_merged_order, 
  meta = Theis_META_order, 
  type = "Deco_type", 
  sample_col = "Run")
```

#### Plot the Data {#Plot}

Now that our data set is prepared, we run `decontam_histo_prev_plots()`. At this point, the threshold we choose doesn't matter. There should be a warning about removing rows containing non-finite values, but that can be ignored.

```{r fig.width=9, fig.height=7, warning= FALSE}
decontam_plots <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.1, study_name = "Theis")
decontam_plots$Histogram
```
This histogram looks at each ASV and gives it a DECONTAM score, which represents how likely it is to be a contaminant. It also indicates the prevalence of each ASV as bars with darker green hue. Finally, ASVs that share the same DECONTAM score are grouped together. 

When determining the appropriate DECONTAM threshold value for low read count samples with a high likelihood of contamination, thresholds less than `0.5` and even less than `0.25` are appropriate. Multiple thresholds can be set to evaluate the extent of conatamination in the data set. For this data set, `0.10` was used as a final threshold since we wanted to keep highly prevalent taxa which had low DECONTAM scores while excluding low prevalence ASVs and ASVs which were highly prevalent in technical controls. At `0.06` and below we can see that ASVs have high prevalence and at `0.17` there is a spike of low prevalence ASVs; the former would be more likely to constitute a placental microbiota than the latter so we set a threshold to exclude the latter ASVs.

```{r fig.width=9, fig.height=7}
decontam_plots$Prevalence_Plot
```

This Prevalence plot lets us take a different look at overall prevalence of taxa. Contaminants in blue are more likely to be found in technical controls than taxa in red. Again, going back and trying different thresholds is recommended.

```{r animation.hook= "gifski", fig.width= 9, fig.height=7}
decontam_plots.5 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.5, study_name = "Theis")
decontam_plots.4 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.4, study_name = "Theis")
decontam_plots.3 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.3, study_name = "Theis")
decontam_plots.2 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.2, study_name = "Theis")
decontam_plots.1 <- decontam_histo_prev_plots(physeq = DECO_prep, thresh = 0.1, study_name = "Theis")
decontam_plots.5$Prevalence_Plot
decontam_plots.4$Prevalence_Plot
decontam_plots.3$Prevalence_Plot
decontam_plots.2$Prevalence_Plot
decontam_plots.1$Prevalence_Plot
```

### Run Decontam with Appropriate Threshold {#Run}

Once a threshold has been chosen, it is time to finally run `decontaminate()`. We still need the original data frame from when we started the process, plus the `Phyloseq` object created when `decontam_prep()` was run.

```{r}

Theis_decontaminated <- decontaminate(df = Theis_merged_order, physeq = DECO_prep, thresh = 0.1)
Theis_true_taxa <- Theis_decontaminated$TrueTaxa
head(Theis_true_taxa[,1:20], 5)

#contaminants can also be evaluated
Theis_contaminants <- Theis_decontaminated$Contaminants
head(Theis_contaminants[,1:20], 5)
```

`decontaminate()` will return a list of three objects (the true taxa, the contaminants, and the threshold which was used), which can each be accessed with `$` after the name of the list. It is important to note that `decontaminate()` uses the `isNotContaminant()` function, which is only appropriate for low biomass sites or low read count sites like the placenta.

***

## Finishing Up {#Finishing}

Now that we have a data set with contaminants removed by DECONTAM, we need to re-plot everything. We can take the `Theis_true_taxa` data set and use the same process to generate PCoA plots, and heatmaps. 

Note that for this pass with a DECONTAMinated data set, it is recommended to use a taxa cutoff in heatmap prep instead of the mean abundance cutoff because DECONTAM filtering will have already modified the taxa proportions by removing contaminant taxa from the data set.

